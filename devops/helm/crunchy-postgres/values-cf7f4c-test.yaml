# TODO: To be removed.
fullnameOverride: simsdb
appuser: app-database-user
nonsuperuser: non-super-user
readonlyuser: read-only-user

crunchyImage: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
#crunchyImage: artifacts.developer.gov.bc.ca/bcgov-docker-local/crunchy-postgres-gis:ubi8-15.2-3.3-0 # use this image for POSTGIS
postgresVersion: 15
#postGISVersion: '3.3' # use this version of POSTGIS. both crunchyImage and this property needs to have valid values for POSTGIS to be enabled.
imagePullPolicy: IfNotPresent

# enable to bootstrap a standby cluster from backup. Then disable to promote this standby to primary
standby:
  enabled: false
  # If you want to recover from PVC, use repo1. If you want to recover from S3, use repo2
  repoName: repo1

# enable this to go back to a specific timestamp in history in the current cluster.
# follow https://access.crunchydata.com/documentation/postgres-operator/5.2.0/tutorial/disaster-recovery/
# Perform an In-Place Point-in-time-Recovery (PITR)
restore:
  enabled: false
  repoName: repo1 # provide repo name
  options:
    target: ~ # 2024-03-24 17:16:00 this is the UTC target timestamp to go back to in current cluster

instances:
  name: ha # high availability
  replicas: 3
  dataVolumeClaimSpec:
    storage: 1.5Gi
    storageClassName: netapp-block-standard
  requests:
    cpu: 25m
    memory: 256Mi
  limits:
    memory: 512Mi
  replicaCertCopy:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      memory: 512Mi

# If we need to restore the cluster from a backup, we need to set the following values
# assuming restore from repo2 (s3), adjust as needed if your S3 repo is different
dataSource:
  enabled: false
  # should have the same name and contain the same keys as the pgbackrest secret
  secretName: pgbackrest-s3
  repo:
    name: repo2
    path: "/habackup-andrew-2"
    s3:
      bucket: "postgres-version-upgrade"
      endpoint: "psfs-sims.objectstore.gov.bc.ca"
      region: "ca-central-1"
    stanza: db

pgBackRest:
  image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
  retention: "30" # Ideally a larger number such as 30 backups/days
  # If retention-full-type set to 'count' then the oldest backups will expire when the number of backups reach the number defined in retention
  # If retention-full-type set to 'time' then the number defined in retention will take that many days worth of full backups before expiration
  retentionFullType: count
  repos:
    schedules:
      full: 0 8 * * *
      incremental: 0 0,4,12,16,20 * * *
    volume:
      accessModes: "ReadWriteOnce"
      storage: 1Gi
      storageClassName: netapp-file-backup
  repoHost:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      memory: 256Mi
  sidecars:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      memory: 256Mi
  s3:
    enabled: true
    createS3Secret: true
    # the s3 secret name
    s3Secret: pgbackrest-s3
    # the path start with /, it will be created under bucket if it doesn't exist
    s3Path: "/habackup-andrew-2"
    # s3UriStyle is host or path
    s3UriStyle: path
    # bucket specifies the S3 bucket to use,
    bucket: "postgres-version-upgrade"
    # endpoint specifies the S3 endpoint to use.
    endpoint: "psfs-sims.objectstore.gov.bc.ca"
    # region specifies the S3 region to use. If your S3 storage system does not
    # use "region", fill this in with a random value.
    region: "ca-central-1"
    # setting the below to be one plus of the default schedule
    # to avoid conflicts
    fullSchedule: "0 9 * * *"
    incrementalSchedule: "0 1,5,13,17,21 * * *"

patroni:
  postgresql:
    pg_hba: "host all all all md5"
    parameters:
      shared_buffers: 128MB # default is 128MB; a good tuned default for shared_buffers is 25% of the memory allocated to the pod
      wal_buffers: "-1" # this can be set to -1 to automatically set as 1/32 of shared_buffers or 64kB, whichever is larger
      min_wal_size: 128MB
      max_wal_size: 1GB # default is 1GB
      max_slot_wal_keep_size: 128MB # default is -1, allowing unlimited wal growth when replicas fall behind

proxy:
  pgBouncer:
    image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
    replicas: 3
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      memory: 256Mi

# Postgres Cluster resource values:
pgmonitor:
  enabled: false
